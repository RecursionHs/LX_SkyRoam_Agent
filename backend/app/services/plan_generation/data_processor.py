"""
æ•°æ®å¤„ç†å’Œæ ¼å¼åŒ–å·¥å…·
"""
import json
import copy
from typing import Dict, Any, List, Optional, Set
from loguru import logger
from types import SimpleNamespace
from datetime import datetime, timedelta

DOMESTIC_KEYWORDS_CN = {
    "ä¸­å›½",
    "å¤§é™†",
    "å†…åœ°",
    "åŒ—äº¬",
    "ä¸Šæµ·",
    "å¹¿å·",
    "æ·±åœ³",
    "æ­å·",
    "å—äº¬",
    "è‹å·",
    "æˆéƒ½",
    "é‡åº†",
    "è¥¿å®‰",
    "æ­¦æ±‰",
    "é•¿æ²™",
    "å¦é—¨",
    "é’å²›",
    "ä¸‰äºš",
    "æµ·å£",
    "æ‹‰è¨",
    "ä¹Œé²æœ¨é½",
}


DOMESTIC_KEYWORDS_EN = {
    "beijing",
    "shanghai",
    "guangzhou",
    "shenzhen",
    "hangzhou",
    "suzhou",
    "nanjing",
    "chengdu",
    "chongqing",
    "wuhan",
    "xiamen",
    "sanya",
    "urumqi",
    "xi'an",
    "xian",
    "qingdao",
    "haikou",
    "lhasa",
    "china",
    "prc",
}

class DataProcessor:
    """æ•°æ®å¤„ç†å™¨"""

    @staticmethod
    def to_datetime(value: Any) -> Optional[datetime]:
        if isinstance(value, datetime):
            return value
        if isinstance(value, str):
            try:
                if date_parser:
                    return date_parser.parse(value)
                return datetime.fromisoformat(value)
            except Exception:
                return None
        return None
    
    @staticmethod
    def format_traffic_info(traffic_conditions: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è·¯å†µä¿¡æ¯"""
        if not traffic_conditions:
            return "æš‚æ— è·¯å†µä¿¡æ¯"
        
        info_parts = []
        
        # æ‹¥å µç¨‹åº¦
        congestion_level = traffic_conditions.get('congestion_level', 'æœªçŸ¥')
        if congestion_level != 'æœªçŸ¥':
            info_parts.append(f"æ‹¥å µç¨‹åº¦: {congestion_level}")
        
        # é“è·¯çŠ¶å†µ
        road_conditions = traffic_conditions.get('road_conditions', [])
        if road_conditions:
            info_parts.append(f"é“è·¯çŠ¶å†µ: {', '.join(road_conditions)}")
        
        # å®æ—¶ä¿¡æ¯
        real_time = traffic_conditions.get('real_time', False)
        if real_time:
            info_parts.append("å®æ—¶è·¯å†µ: æ˜¯")
        
        return ', '.join(info_parts) if info_parts else "æš‚æ— è·¯å†µä¿¡æ¯"

    @staticmethod
    def format_data_for_llm(data: List[Dict[str, Any]], data_type: str) -> str:
        """æ ¼å¼åŒ–æ•°æ®ä¾›LLMä½¿ç”¨"""
        if not data:
            return "æš‚æ— æ•°æ®"
        
        formatted_items = []
        for i, item in enumerate(data[:10]):  # é™åˆ¶æ•°é‡ï¼Œé¿å…promptè¿‡é•¿
            if data_type == 'flight':
                # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
                departure_time = item.get('departure_time', 'N/A')
                arrival_time = item.get('arrival_time', 'N/A')
                if departure_time != 'N/A' and 'T' in departure_time:
                    departure_time = departure_time.split('T')[1][:5]  # åªæ˜¾ç¤ºæ—¶é—´éƒ¨åˆ† HH:MM
                if arrival_time != 'N/A' and 'T' in arrival_time:
                    arrival_time = arrival_time.split('T')[1][:5]  # åªæ˜¾ç¤ºæ—¶é—´éƒ¨åˆ† HH:MM
                
                # æ ¼å¼åŒ–ä»·æ ¼æ˜¾ç¤º
                price_display = "N/A"
                if item.get('price_cny'):
                    price_display = f"{item.get('price_cny')}å…ƒ"
                elif item.get('price'):
                    currency = item.get('currency', 'CNY')
                    price_display = f"{item.get('price')}{currency}"
                
                # ä¸­è½¬ä¿¡æ¯
                stops = item.get('stops', 0)
                stops_text = "ç›´é£" if stops == 0 else f"{stops}æ¬¡ä¸­è½¬"
                
                formatted_items.append(f"""
  {i+1}. èˆªç­å·: {item.get('flight_number', 'N/A')}
     èˆªç©ºå…¬å¸: {item.get('airline_name', item.get('airline', 'N/A'))}
     å‡ºå‘æ—¶é—´: {departure_time}
     åˆ°è¾¾æ—¶é—´: {arrival_time}
     é£è¡Œæ—¶é•¿: {item.get('duration', 'N/A')}
     ä»·æ ¼: {price_display}
     èˆ±ä½ç­‰çº§: {item.get('cabin_class', 'N/A')}
     ä¸­è½¬æƒ…å†µ: {stops_text}
     å‡ºå‘æœºåœº: {item.get('origin', 'N/A')}
     åˆ°è¾¾æœºåœº: {item.get('destination', 'N/A')}
     è¡Œæé¢åº¦: {item.get('baggage_allowance', 'N/A')}""")
            
            elif data_type == 'hotel':
                formatted_items.append(f"""
  {i+1}. é…’åº—åç§°: {item.get('name', 'N/A')}
     åœ°å€: {item.get('address', 'N/A')}
     æ¯æ™šä»·æ ¼: {item.get('price_per_night', 'N/A')}å…ƒ
     è¯„åˆ†: {item.get('rating', 'N/A')}
     è®¾æ–½: {', '.join(item.get('amenities', []))}
     æ˜Ÿçº§: {item.get('star_rating', 'N/A')}""")
            
            elif data_type == 'attraction':
                # å¢å¼ºæ™¯ç‚¹ä¿¡æ¯æ ¼å¼åŒ–ï¼ŒåŒ…å«ç™¾åº¦åœ°å›¾çš„è¯¦ç»†ä¿¡æ¯
                formatted_items.append(f"""
  {i+1}. æ™¯ç‚¹åç§°: {item.get('name', 'N/A')}
     ç±»å‹: {item.get('category', 'N/A')}
     æè¿°: {item.get('description', 'N/A')}
     é—¨ç¥¨ä»·æ ¼: {item.get('price', 'N/A')}å…ƒ
     è¯„åˆ†: {item.get('rating', 'N/A')}
     åœ°å€: {item.get('address', 'N/A')}
     å¼€æ”¾æ—¶é—´: {item.get('opening_hours', 'N/A')}
     å»ºè®®æ¸¸è§ˆæ—¶é—´: {item.get('visit_duration', 'N/A')}
     ç‰¹è‰²æ ‡ç­¾: {', '.join(item.get('tags', []))}
     è”ç³»æ–¹å¼: {item.get('phone', 'N/A')}
     å®˜æ–¹ç½‘ç«™: {item.get('website', 'N/A')}
     äº¤é€šä¾¿åˆ©æ€§: {item.get('accessibility', 'N/A')}
     æ•°æ®æ¥æº: {item.get('source', 'N/A')}""")
            
            elif data_type == 'restaurant':
                formatted_items.append(f"""
  {i+1}. é¤å…åç§°: {item.get('name', 'N/A')}
     èœç³»: {item.get('cuisine', 'N/A')}
     å‚è€ƒæ¶ˆè´¹: {item.get('price_range', 'ä»·æ ¼æœªçŸ¥')}
     è¯„åˆ†: {item.get('rating', 'N/A')}
     åœ°å€: {item.get('address', 'N/A')}
     ç‰¹è‰²èœ: {', '.join(item.get('specialties', []))}""")
            
            elif data_type == 'transportation':
                # å¢å¼ºäº¤é€šä¿¡æ¯æ ¼å¼åŒ–ï¼ŒåŒ…å«ç™¾åº¦åœ°å›¾çš„è¯¦ç»†ä¿¡æ¯
                formatted_items.append(f"""
  {i+1}. äº¤é€šæ–¹å¼: {item.get('type', 'N/A')}
     åç§°: {item.get('name', 'N/A')}
     æè¿°: {item.get('description', 'N/A')}
     è·ç¦»: {item.get('distance', 'N/A')}å…¬é‡Œ
     è€—æ—¶: {item.get('duration', 'N/A')}åˆ†é’Ÿ
     è´¹ç”¨: {item.get('price', item.get('cost', 'N/A'))}å…ƒ
     è´§å¸: {item.get('currency', 'CNY')}
     è¿è¥æ—¶é—´: {item.get('operating_hours', 'N/A')}
     å‘è½¦é¢‘ç‡: {item.get('frequency', 'N/A')}
     è¦†ç›–åŒºåŸŸ: {', '.join(item.get('coverage', []))}
     ç‰¹è‰²åŠŸèƒ½: {', '.join(item.get('features', []))}
     è·¯çº¿: {item.get('route', 'N/A')}
     æ•°æ®æ¥æº: {item.get('source', 'N/A')}
     è·¯å†µä¿¡æ¯: {DataProcessor.format_traffic_info(item.get('traffic_conditions', {}))}""")
        
        return '\n'.join(formatted_items) if formatted_items else "æš‚æ— æ•°æ®"
    
    @staticmethod
    def format_xiaohongshu_data_for_prompt(notes: List[Dict[str, Any]], destination: str) -> str:
        """æ ¼å¼åŒ–å°çº¢ä¹¦æ•°æ®ä¸ºæç¤ºæ–‡æœ¬"""
        if not notes:
            return f"æš‚æ— {destination}çš„å°çº¢ä¹¦ç”¨æˆ·åˆ†äº«å†…å®¹"
        
        formatted_notes = []
        for note in notes[:5]:  # é™åˆ¶æ•°é‡
            title = note.get('title', 'æ— æ ‡é¢˜')
            content = note.get('content', '')
            if len(content) > 200:
                content = content[:200] + "..."
            
            formatted_note = f"ğŸ“ {title}\n{content}"
            formatted_notes.append(formatted_note)
        
        return "\n\n".join(formatted_notes)
    
    @staticmethod
    def build_lookup_map(items: Optional[List[Dict[str, Any]]]) -> Dict[str, Dict[str, Any]]:
        """æ„å»ºæŸ¥æ‰¾æ˜ å°„è¡¨"""
        if not items:
            return {}
        
        lookup_map = {}
        for item in items:
            if isinstance(item, dict):
                name = item.get("name")
                if name:
                    lookup_map[name.lower().strip()] = item
        
        return lookup_map
    
    @staticmethod
    def find_lookup_match(lookup: Dict[str, Dict[str, Any]], target: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """åœ¨æŸ¥æ‰¾è¡¨ä¸­æ‰¾åˆ°åŒ¹é…é¡¹"""
        if not target or not lookup:
            return None
        
        target_name = target.get("name", "").lower().strip()
        if not target_name:
            return None
        
        # ç²¾ç¡®åŒ¹é…
        if target_name in lookup:
            return lookup[target_name]
        
        # æ¨¡ç³ŠåŒ¹é…
        for key, value in lookup.items():
            if target_name in key or key in target_name:
                return value
        
        return None
    
    @staticmethod
    def combine_detail_dicts(
        source: Dict[str, Any],
        override: Dict[str, Any],
        list_fields: Set[str]
    ) -> Dict[str, Any]:
        """åˆå¹¶è¯¦ç»†ä¿¡æ¯å­—å…¸"""
        merged = copy.deepcopy(source) if source else {}
        if not override:
            return merged

        for key, value in override.items():
            if key in list_fields:
                merged[key] = DataProcessor.merge_list_values(merged.get(key), value)
            else:
                if value not in (None, "", [], {}):
                    merged[key] = value
        return merged
    
    @staticmethod
    def merge_list_values(existing: Any, extra: Any) -> List[Any]:
        """åˆå¹¶åˆ—è¡¨å€¼ï¼Œå»é‡"""
        result = []
        seen = set()

        for collection in (existing, extra):
            for item in DataProcessor.ensure_list(collection):
                marker = DataProcessor.make_hashable(item)
                if marker in seen:
                    continue
                seen.add(marker)
                result.append(item)
        return result
    
    @staticmethod
    def ensure_list(value: Any) -> List[Any]:
        """ç¡®ä¿è¿”å›åˆ—è¡¨ç±»å‹"""
        if value is None or value == "":
            return []
        if isinstance(value, list):
            return value
        return [value]
    
    @staticmethod
    def make_hashable(value: Any) -> str:
        """å°†å€¼è½¬æ¢ä¸ºå¯å“ˆå¸Œçš„å­—ç¬¦ä¸²"""
        try:
            return json.dumps(value, sort_keys=True, ensure_ascii=False)
        except TypeError:
            return str(value)
    
    @staticmethod
    def normalize_resource_name(name: Optional[str]) -> str:
        """æ ‡å‡†åŒ–èµ„æºåç§°ç”¨äºå»é‡"""
        if not name:
            return ""
        
        # ç§»é™¤å¸¸è§çš„å“ç‰Œåç¼€ã€è¿é”æ ‡è¯†ç­‰
        normalized = str(name).lower().strip()
        suffixes_to_remove = [
            "é…’åº—", "å®¾é¦†", "æ—…é¦†", "åº¦å‡æ‘", "æ°‘å®¿",
            "é¤å…", "é¥­åº—", "é£Ÿåºœ", "æ–™ç†", "çƒ¤è‚‰",
            "æ™¯åŒº", "å…¬å›­", "æ™¯ç‚¹", "åšç‰©é¦†", "çºªå¿µé¦†",
            "åº—", "é¦†", "ä¸­å¿ƒ", "å¹¿åœº", "å¸‚åœº", "è¡—"
        ]
        
        for suffix in suffixes_to_remove:
            if normalized.endswith(suffix):
                normalized = normalized[:-len(suffix)]
        
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œæ•°å­—
        import re
        normalized = re.sub(r'[^\w\u4e00-\u9fff]', '', normalized)
        
        return normalized.strip()
    
    @staticmethod
    def clean_llm_response(response: str) -> str:
        """æ¸…ç†LLMå“åº”ï¼Œç§»é™¤markdownæ ‡è®°ç­‰"""
        import re
        
        # ç§»é™¤markdownä»£ç å—æ ‡è®°
        cleaned = re.sub(r'```json\s*', '', response)
        cleaned = re.sub(r'```\s*$', '', cleaned)
        cleaned = re.sub(r'```\s*', '', cleaned)  # ç§»é™¤å•ç‹¬çš„```
        
        # ç§»é™¤å‰åçš„ç©ºç™½å­—ç¬¦
        cleaned = cleaned.strip()
        
        return cleaned
    
    @staticmethod
    def merge_total_cost(base: Dict[str, Any], segment: Dict[str, Any]) -> None:
        base_cost = base.get("total_cost")
        seg_cost = segment.get("total_cost")
        if not isinstance(seg_cost, dict):
            return
        if not isinstance(base_cost, dict):
            base_cost = {}
        for key, value in seg_cost.items():
            if isinstance(value, (int, float)):
                base_cost[key] = base_cost.get(key, 0) + value
            else:
                base_cost[key] = value
        base["total_cost"] = base_cost

    @staticmethod
    def build_segment_plan(
        plan: Any,
        segment: Dict[str, Any],
        preferences: Optional[Dict[str, Any]],
        segment_budget: Optional[float],
    ) -> Any:
        base_attrs = {
            "id": getattr(plan, "id", None),
            "title": getattr(plan, "title", None),
            "description": getattr(plan, "description", None),
            "departure": getattr(plan, "departure", None),
            "destination": getattr(plan, "destination", None),
            "transportation": getattr(plan, "transportation", None),
            "requirements": getattr(plan, "requirements", None),
            "num_people": getattr(plan, "num_people", None)
            or (preferences or {}).get("travelers")
            or getattr(plan, "travelers", None),
            "age_group": getattr(plan, "age_group", None),
            "travelers": getattr(plan, "travelers", None)
            or (preferences or {}).get("travelers"),
            "user_id": getattr(plan, "user_id", None),
            "status": getattr(plan, "status", None),
            "score": getattr(plan, "score", None),
            "is_public": getattr(plan, "is_public", None),
            "public_at": getattr(plan, "public_at", None),
        }
        base_attrs.update(
            {
                "duration_days": segment["days"],
                "start_date": segment["start_date"],
                "end_date": segment["end_date"],
                "budget": segment_budget,
            }
        )
        return SimpleNamespace(**base_attrs)

    @staticmethod
    def deduplicate_daily_attractions(plan_data: Dict[str, Any], min_attractions_per_day: int) -> None:
        """åœ¨åŒä¸€æ–¹æ¡ˆå†…æŒ‰å¤©å»é‡æ™¯ç‚¹ï¼Œé¿å…åŒä¸€æ™¯ç‚¹å‡ºç°åœ¨å¤šä¸ªæ—¥æœŸ.

        æ™ºèƒ½å»é‡ç­–ç•¥ï¼š
        1. å¦‚æœæ™¯ç‚¹æ€»æ•°å……è¶³ï¼Œä¸¥æ ¼å»é‡ï¼Œç¡®ä¿æ¯ä¸ªæ™¯ç‚¹åªå‡ºç°ä¸€æ¬¡
        2. å¦‚æœæ™¯ç‚¹æ€»æ•°ä¸è¶³ï¼Œä¼˜å…ˆä¿ç•™æœªä½¿ç”¨çš„æ™¯ç‚¹ï¼Œä½†å…è®¸é‡å¤ä½¿ç”¨ä»¥å¡«æ»¡æ¯å¤©çš„æœ€å°‘æ™¯ç‚¹æ•°
        
        ä»…ä¾é æ™¯ç‚¹åç§°è¿›è¡Œå»é‡ï¼Œåç§°ä¸ºç©ºæˆ–æ— æ³•è§£æçš„æ¡ç›®åŸæ ·ä¿ç•™ã€‚
        è¯¥å‡½æ•°ä¼šåŸåœ°ä¿®æ”¹ plan_data ä¸­çš„ daily_itinerariesã€‚
        """
        try:
            daily_itineraries = plan_data.get("daily_itineraries", []) or []
            if not daily_itineraries:
                return
            
            # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰æ™¯ç‚¹å¹¶ç»Ÿè®¡å”¯ä¸€æ™¯ç‚¹æ€»æ•°
            all_attractions: List[tuple] = []  # (attraction_obj, normalized_name)
            for day in daily_itineraries:
                attractions = day.get("attractions") or []
                if not isinstance(attractions, list):
                    continue
                for attr in attractions:
                    name = None
                    if isinstance(attr, dict):
                        name = attr.get("name")
                    elif isinstance(attr, str):
                        name = attr
                    normalized = DataProcessor.normalize_resource_name(name)
                    if normalized:  # åªç»Ÿè®¡æœ‰åå­—çš„æ™¯ç‚¹
                        all_attractions.append((attr, normalized))
            
            # ç»Ÿè®¡å”¯ä¸€æ™¯ç‚¹æ•°é‡
            unique_attraction_names = set(norm for _, norm in all_attractions)
            total_unique = len(unique_attraction_names)
            total_days = len(daily_itineraries)
            
            # å¦‚æœå”¯ä¸€æ™¯ç‚¹æ•°è¶³å¤Ÿï¼Œä½¿ç”¨ä¸¥æ ¼å»é‡
            required_total = total_days * min_attractions_per_day
            if total_unique >= required_total:
                seen = set()
                for day in daily_itineraries:
                    attractions = day.get("attractions") or []
                    if not isinstance(attractions, list):
                        continue
                    unique = []
                    for attr in attractions:
                        name = None
                        if isinstance(attr, dict):
                            name = attr.get("name")
                        elif isinstance(attr, str):
                            name = attr
                        normalized = DataProcessor.normalize_resource_name(name)
                        # æ²¡æœ‰åå­—çš„ï¼Œæˆ–è€…æœªè§è¿‡çš„ï¼Œç›´æ¥ä¿ç•™
                        if not normalized or normalized not in seen:
                            unique.append(attr)
                            if normalized:
                                seen.add(normalized)
                    day["attractions"] = unique
                logger.info(f"æ™¯ç‚¹å……è¶³({total_unique}ä¸ªå”¯ä¸€æ™¯ç‚¹ï¼Œéœ€è¦{required_total}ä¸ª)ï¼Œå·²ä¸¥æ ¼å»é‡")
            else:
                # æ™¯ç‚¹ä¸è¶³ï¼Œä½¿ç”¨æ™ºèƒ½å»é‡ç­–ç•¥
                logger.info(f"æ™¯ç‚¹ä¸è¶³({total_unique}ä¸ªå”¯ä¸€æ™¯ç‚¹ï¼Œéœ€è¦{required_total}ä¸ª)ï¼Œå¯ç”¨æ™ºèƒ½å»é‡ç­–ç•¥")
                
                # è®°å½•æ¯ä¸ªæ™¯ç‚¹çš„ä½¿ç”¨æ¬¡æ•°
                usage_count = {}
                # å»ºç«‹æ™¯ç‚¹å¯¹è±¡åˆ°åç§°çš„æ˜ å°„
                attr_to_name = {}  # ä½¿ç”¨id(attr)ä½œä¸ºkey
                
                # ç¬¬ä¸€éï¼šä¼˜å…ˆä¿ç•™æœªä½¿ç”¨çš„æ™¯ç‚¹ï¼Œç»Ÿè®¡ä½¿ç”¨æ¬¡æ•°
                seen = set()
                for day in daily_itineraries:
                    attractions = day.get("attractions") or []
                    if not isinstance(attractions, list):
                        continue
                    unique = []
                    for attr in attractions:
                        name = None
                        if isinstance(attr, dict):
                            name = attr.get("name")
                        elif isinstance(attr, str):
                            name = attr
                        normalized = DataProcessor.normalize_resource_name(name)
                        
                        if not normalized:
                            # æ²¡æœ‰åå­—çš„ï¼Œç›´æ¥ä¿ç•™
                            unique.append(attr)
                        elif normalized not in seen:
                            # æœªä½¿ç”¨è¿‡çš„ï¼Œä¼˜å…ˆä¿ç•™
                            unique.append(attr)
                            seen.add(normalized)
                            usage_count[normalized] = 1
                            attr_to_name[id(attr)] = normalized
                        else:
                            # å·²ä½¿ç”¨è¿‡çš„ï¼Œè®°å½•ä½¿ç”¨æ¬¡æ•°
                            usage_count[normalized] = usage_count.get(normalized, 0) + 1
                            attr_to_name[id(attr)] = normalized
                    
                    day["attractions"] = unique
                
                # ç¬¬äºŒéï¼šå¦‚æœæŸå¤©æ™¯ç‚¹æ•°ä¸è¶³ï¼Œä»å·²ä½¿ç”¨çš„æ™¯ç‚¹ä¸­è¡¥å……ï¼ˆä¼˜å…ˆé€‰æ‹©ä½¿ç”¨æ¬¡æ•°æœ€å°‘çš„ï¼‰
                for day in daily_itineraries:
                    attractions = day.get("attractions") or []
                    if not isinstance(attractions, list):
                        continue
                    
                    current_count = len([a for a in attractions if DataProcessor.normalize_resource_name(
                        a.get("name") if isinstance(a, dict) else (a if isinstance(a, str) else None)
                    )])
                    
                    # å¦‚æœå½“å‰æ™¯ç‚¹æ•°å°‘äºæœ€å°‘è¦æ±‚ï¼Œéœ€è¦è¡¥å……
                    if current_count < min_attractions_per_day:
                        needed = min_attractions_per_day - current_count
                        
                        # æ‰¾å‡ºæ‰€æœ‰å·²ä½¿ç”¨çš„æ™¯ç‚¹ï¼ŒæŒ‰ä½¿ç”¨æ¬¡æ•°æ’åºï¼ˆä½¿ç”¨æ¬¡æ•°å°‘çš„ä¼˜å…ˆï¼‰
                        available_attrs = [
                            (norm, count) for norm, count in usage_count.items()
                            if norm in seen  # åªè€ƒè™‘å·²ä½¿ç”¨è¿‡çš„
                        ]
                        available_attrs.sort(key=lambda x: x[1])  # æŒ‰ä½¿ç”¨æ¬¡æ•°å‡åº
                        
                        # ä»ä½¿ç”¨æ¬¡æ•°æœ€å°‘çš„æ™¯ç‚¹ä¸­é€‰æ‹©è¡¥å……
                        for norm, _ in available_attrs[:needed]:
                            # ä»åŸå§‹æ•°æ®ä¸­æ‰¾åˆ°å¯¹åº”çš„æ™¯ç‚¹å¯¹è±¡
                            for orig_attr, orig_norm in all_attractions:
                                if orig_norm == norm:
                                    # åˆ›å»ºå‰¯æœ¬ï¼Œé¿å…å¼•ç”¨é—®é¢˜
                                    if isinstance(orig_attr, dict):
                                        attr_copy = copy.deepcopy(orig_attr)
                                    else:
                                        attr_copy = orig_attr
                                    attractions.append(attr_copy)
                                    usage_count[norm] = usage_count.get(norm, 0) + 1
                                    break
                        
                        day["attractions"] = attractions
                
                logger.info(f"æ™ºèƒ½å»é‡å®Œæˆï¼Œéƒ¨åˆ†æ™¯ç‚¹å…è®¸é‡å¤ä½¿ç”¨ä»¥å¡«æ»¡æ¯å¤©æœ€å°‘{min_attractions_per_day}ä¸ªæ™¯ç‚¹çš„è¦æ±‚")
                
        except Exception as e:  # é˜²å¾¡æ€§ï¼Œä»»ä½•å¼‚å¸¸ä¸å½±å“ä¸»æµç¨‹
            logger.warning(f"å»é‡æ¯æ—¥æ™¯ç‚¹å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())

    @staticmethod
    def format_weather_info(weather_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¼å¼åŒ–å¤©æ°”ä¿¡æ¯"""
        if not weather_data:
            return {
                "raw_data": {},
                "travel_recommendations": ["æš‚æ— å¤©æ°”æ•°æ®ï¼Œå»ºè®®å‡ºè¡Œå‰æŸ¥çœ‹æœ€æ–°å¤©æ°”é¢„æŠ¥"]
            }
        
        # ç”ŸæˆåŸºäºå¤©æ°”çš„æ—…æ¸¸å»ºè®®
        recommendations = []
        
        # æ£€æŸ¥æ¸©åº¦
        temp = weather_data.get('temperature')
        if temp:
            if isinstance(temp, (int, float)):
                if temp < 10:
                    recommendations.append("æ°”æ¸©è¾ƒä½ï¼Œå»ºè®®ç©¿ç€ä¿æš–è¡£ç‰©ï¼Œæºå¸¦å¤–å¥—")
                elif temp > 30:
                    recommendations.append("æ°”æ¸©è¾ƒé«˜ï¼Œå»ºè®®ç©¿ç€è½»è–„é€æ°”è¡£ç‰©ï¼Œæ³¨æ„é˜²æ™’")
                else:
                    recommendations.append("æ°”æ¸©é€‚å®œï¼Œå»ºè®®ç©¿ç€èˆ’é€‚çš„ä¼‘é—²æœè£…")
        
        # æ£€æŸ¥å¤©æ°”çŠ¶å†µ
        weather_desc = weather_data.get('weather', '').lower()
        if 'é›¨' in weather_desc or 'rain' in weather_desc:
            recommendations.append("æœ‰é™é›¨ï¼Œå»ºè®®æºå¸¦é›¨å…·ï¼Œé€‰æ‹©å®¤å†…æ™¯ç‚¹æˆ–æœ‰é®è”½çš„æ´»åŠ¨")
        elif 'é›ª' in weather_desc or 'snow' in weather_desc:
            recommendations.append("æœ‰é™é›ªï¼Œæ³¨æ„ä¿æš–é˜²æ»‘ï¼Œé€‰æ‹©é€‚åˆé›ªå¤©çš„æ´»åŠ¨")
        elif 'æ™´' in weather_desc or 'sunny' in weather_desc:
            recommendations.append("å¤©æ°”æ™´æœ—ï¼Œé€‚åˆæˆ·å¤–æ´»åŠ¨å’Œè§‚å…‰ï¼Œæ³¨æ„é˜²æ™’")
        elif 'äº‘' in weather_desc or 'cloud' in weather_desc:
            recommendations.append("å¤šäº‘å¤©æ°”ï¼Œé€‚åˆå„ç§æˆ·å¤–æ´»åŠ¨ï¼Œå…‰çº¿æŸ”å’Œé€‚åˆæ‹ç…§")
        
        # æ£€æŸ¥æ¹¿åº¦
        humidity = weather_data.get('humidity')
        if humidity and isinstance(humidity, (int, float)):
            if humidity > 80:
                recommendations.append("æ¹¿åº¦è¾ƒé«˜ï¼Œå»ºè®®é€‰æ‹©é€æ°”æ€§å¥½çš„è¡£ç‰©")
            elif humidity < 30:
                recommendations.append("æ¹¿åº¦è¾ƒä½ï¼Œæ³¨æ„è¡¥æ°´ä¿æ¹¿")
        
        # æ£€æŸ¥é£åŠ›
        wind_speed = weather_data.get('wind_speed')
        if wind_speed and isinstance(wind_speed, (int, float)):
            if wind_speed > 20:
                recommendations.append("é£åŠ›è¾ƒå¤§ï¼Œæˆ·å¤–æ´»åŠ¨æ—¶æ³¨æ„å®‰å…¨ï¼Œé¿å…é«˜ç©ºé¡¹ç›®")
        
        # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•å»ºè®®ï¼Œæ·»åŠ é»˜è®¤å»ºè®®
        if not recommendations:
            recommendations.append("å»ºè®®æ ¹æ®å½“åœ°å¤©æ°”æƒ…å†µåˆç†å®‰æ’è¡Œç¨‹")
        
        return {
            "raw_data": weather_data,
            "travel_recommendations": recommendations
        }

    @staticmethod
    def infer_scope_from_metadata(plan: Any, destination: str) -> Optional[str]:
        """ä¼˜å…ˆä¾æ®æ˜¾å¼å›½å®¶å­—æ®µå’Œå…³é”®è¯åˆ¤æ–­"""
        country = getattr(plan, "country", None)
        if country:
            normalized_country = str(country).strip().lower()
            if normalized_country in {"china", "cn", "prc", "ä¸­åäººæ°‘å…±å’Œå›½", "ä¸­å›½"}:
                return "domestic"
            return "international"

        text_lower = destination.lower()
        if any(keyword in destination for keyword in DOMESTIC_KEYWORDS_CN):
            return "domestic"
        if any(keyword in text_lower for keyword in DOMESTIC_KEYWORDS_EN):
            return "domestic"

        if destination and all(ord(ch) < 128 for ch in destination) and not any(
            keyword in text_lower for keyword in DOMESTIC_KEYWORDS_EN
        ):
            return "international"
        return None

    @staticmethod
    def normalize_preferences(preferences: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """ç¡®ä¿åå¥½å­—æ®µå­˜åœ¨å¹¶æ ¼å¼æ­£ç¡®"""
        normalized = dict(preferences or {})

        def _set_default_list(key: str):
            value = normalized.get(key)
            if value is None:
                normalized[key] = []
            elif not isinstance(value, list):
                normalized[key] = [value]

        def _set_default_int(key: str, default: int = 1):
            value = normalized.get(key)
            if value is None:
                normalized[key] = default
                return
            try:
                normalized[key] = int(value)
            except (TypeError, ValueError):
                normalized[key] = default

        _set_default_int("travelers", 1)
        _set_default_list("ageGroups")
        _set_default_list("foodPreferences")
        _set_default_list("dietaryRestrictions")

        return normalized